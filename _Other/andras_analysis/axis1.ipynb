{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8444475",
   "metadata": {},
   "source": [
    "# <center> Punchlines as Mirrors: Social Attitudes, Politics, and Biases in the *The New Yorker* Caption Contest\n",
    "\n",
    "Humor reflects society’s views, stereotypes, and political climate. The New Yorker Caption Contest offers a unique lens into this process, showing what people find acceptable, absurd, or taboo.\n",
    "\n",
    "## <center> Narrative Flow\n",
    "- **Introduction:** The Caption Contest as a cultural mirror — humor as social data.\n",
    "- **Axis 1:** Professions & politics → humor about authority and power, *“What are people laughing about?”*\n",
    "- **Axis 2:** Humor in time → historical & contextual dimensions, *“When and why do jokes resonate?”*\n",
    "- **Axis 3:** Social norms → gender roles & taboos, testing the limits of humor, *“What’s acceptable or not?”*\n",
    "- **Axis 4:** Biases → explain psychological and cultural mechanisms behind why we laugh, *“Why do we find it funny?”*\n",
    "- **Conclusion:** Humor not only entertains — it reveals evolving attitudes, biases, and the cultural pulse of society.\n",
    "\n",
    "> **Idea for website:** Each section should begin with a set of cartoons from the contest to immerse the viewer in humor before moving to analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## <center> Axes of Research\n",
    "\n",
    "### <center> 1. Professions, Politics, and Power\n",
    "\n",
    "- **Professions in Humor:** Which jobs are depicted most often? Which are ridiculed vs. admired? What stereotypes recur (e.g., lawyers as tricksters, doctors as saviors)?\n",
    "- **Politics in Humor:** Do captions reflect partisan leanings (Democrat vs. Republican) or mock political figures more broadly? Are political jokes rated differently?\n",
    "- **Interplay:** Professions like politicians or lawyers sit at the crossroads of both — this axis highlights how authority and social roles are viewed through humor.\n",
    "\n",
    "**Plots / Statistics:**\n",
    "- Bar / Word Clouds: Frequency of professions mentioned in captions (“doctor,” “lawyer,” “politician”).\n",
    "- Histograms / Line Plots: Frequency of professions across time.\n",
    "- Grouped Bar Charts: Average funniness scores by profession category (healthcare, law, politics, education, etc.).\n",
    "- Heatmaps: Cross-tab professions × sentiment (positive/negative/neutral).\n",
    "- Cartoon + Caption Samples: A few annotated cartoons showing how professions are ridiculed.\n",
    "\n",
    "**For Politics:**\n",
    "- Timeline of mentions of political figures/parties.\n",
    "- Sentiment distribution around Democrats vs. Republicans.\n",
    "- Example “political joke clusters” side by side with major events (e.g., elections).\n",
    "\n",
    "**Statistical Tests & Models:**\n",
    "- t-tests / z-tests → Compare funniness scores of politicians vs. other professions.\n",
    "- Multiple hypothesis testing (FDR/BH) → Control for comparisons across 30+ job categories.\n",
    "- Network graphs → Co-occurrence of profession keywords with stereotypes (“lawyer–money,” “doctor–death”).\n",
    "- Linear regression / lmplot → Test if political humor ratings rise around elections.\n",
    "- Pearsonr / Spearmanr → Correlation between real-world political cycles and joke frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b810820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andra\\OneDrive\\Desktop\\MA1_2025-2026\\Applied_data_analysis\\project\\ada-2025-project-adacore42\\_Other\\andras_analysis\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65bea75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\andra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\andra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Loading packages (hopefully installed, all is correct version and whatnot)\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Statistical analysis\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Language processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import textblob as TextBlob\n",
    "import contractions\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')       # Tokeniser\n",
    "nltk.download('stopwords')   # Stopwords list\n",
    "nltk.download('wordnet')     # Lemmatiser\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # Initialise stopwords\n",
    "lemmatizer = WordNetLemmatizer() # Initialise lemmatiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d7bc2",
   "metadata": {},
   "source": [
    "---\n",
    "# <center> Preparing the Data\n",
    "\n",
    "In this section, the code will preprocess the text of the captions and create a tokenized column suitable for analysis. The preprocessing steps include:\n",
    "\n",
    "- Converting all text to **lower-case**  \n",
    "- Removing **stopwords**  \n",
    "- Eliminating **punctuation** such as dots and commas  \n",
    "- **Expanding contractions**, e.g., “don’t” → “do not”, “it’s” → “it is”  \n",
    "- **Correcting typos** to standardize common misspellings (optional but recommended for cleaner analysis)  \n",
    "- **Removing very short tokens** (e.g., single letters or extremely short words)  \n",
    "- **Lemmatizing words** to reduce them to their base forms, e.g., “running” → “run”, “better” → “good”  \n",
    "\n",
    "These steps will prepare the captions for downstream analyses, such as frequency counts, word clouds, sentiment analysis, and extraction of professions or topics from the text.\n",
    "\n",
    "I will only run this cell once, and save the outcome data in a new file, still within my folder here for the time being. For future work, there will be no need to do this work again. Then, I think this data should be added to the datapreparation step, as I am not doing anything fundamentally bad. I am creating new columns in the dataframes, so only the data becomes larger.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554106f5",
   "metadata": {},
   "source": [
    "The code is in a __text__ file, it is not necessary to see here. the function to tokenise is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24cef2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_list(entry, min_len=2):\n",
    "    \"\"\"Preprocess a list of text entries or a single string.\"\"\"\n",
    "    if isinstance(entry, list):\n",
    "        text = \" \".join(entry)\n",
    "    elif isinstance(entry, str):\n",
    "        text = entry\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # Typo correction\n",
    "    text = str(TextBlob(text).correct())\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and short tokens\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) >= min_len]\n",
    "\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "492d9b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load clean data\n",
    "fullldata = '../../data/cleaned_data_prepared.pkl'\n",
    "with open(fullldata, \"rb\") as f:\n",
    "    cleaned_stored_data = pickle.load(f)\n",
    "print(\"Cleaned data loaded successfully.\")\n",
    "dataA_cleaned = cleaned_stored_data[\"dataA\"]\n",
    "dataC_cleaned = cleaned_stored_data[\"dataC\"]\n",
    "dataA_startID = cleaned_stored_data[\"dataA_startID\"]\n",
    "dataA_endID = cleaned_stored_data[\"dataA_endID\"]\n",
    "dataC_lastGoodID = cleaned_stored_data[\"dataC_lastGoodID\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e51f5c",
   "metadata": {},
   "source": [
    "---\n",
    "# <center> Professions in Humor\n",
    "\n",
    "In this section, we will focus on how different professions are depicted in *The New Yorker* Caption Contest captions. Humor often reflects societal attitudes toward authority, expertise, and social roles, and professions provide a lens into these perceptions.  \n",
    "\n",
    "## <center> Key Points\n",
    "- **Frequency of depiction:** Which jobs appear most often in captions?  \n",
    "- **Stereotypes:** How are certain professions portrayed — are they admired, ridiculed, or caricatured?  \n",
    "  - Example stereotypes: lawyers as tricksters, doctors as saviors.  \n",
    "- **Interplay with politics:** Some professions, like politicians or lawyers, intersect with both professional and political commentary, highlighting how authority and social power are perceived.  \n",
    "\n",
    "## <center> Analytical Approach\n",
    "To study professions in humor, we will:\n",
    "- Count the number of times each profession is mentioned across all captions.  \n",
    "- Visualize the distribution with **bar charts** or **word clouds**.  \n",
    "- Examine sentiment associated with professions using **heatmaps**.  \n",
    "- Compare average “funniness” scores by profession category to see which roles tend to be funnier.  \n",
    "- Annotate examples of cartoons and captions to illustrate recurring jokes and stereotypes.\n",
    "\n",
    "> This analysis will help us answer the question: *“What are people laughing about when it comes to professions?”*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77b6e7",
   "metadata": {},
   "source": [
    "We are only dealing with nouns when depicting jobs, so, as a first step, we need to extract all nouns from our captions. This will essentially reduce the size of the dataset and save us some more time. To do this, I will use the nltk package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a80dd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_cleaned0 = dataA_cleaned.copy()\n",
    "dataC_cleaned0 = dataC_cleaned.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1e326f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_cleaned0[0].loc[0, 'cleaned_caption'] = 'congressmen obstruction job'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aaf10071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting nouns .......... 0.26% complete.\n",
      "Extracting nouns .......... 0.52% complete.\n",
      "Extracting nouns .......... 0.78% complete.\n",
      "Extracting nouns .......... 1.04% complete.\n",
      "Extracting nouns .......... 1.30% complete.\n",
      "Extracting nouns .......... 1.56% complete.\n",
      "Extracting nouns .......... 1.82% complete.\n",
      "Extracting nouns .......... 2.08% complete.\n",
      "Extracting nouns .......... 2.34% complete.\n",
      "Extracting nouns .......... 2.60% complete.\n",
      "Extracting nouns .......... 2.86% complete.\n",
      "Extracting nouns .......... 3.12% complete.\n",
      "Extracting nouns .......... 3.39% complete.\n",
      "Extracting nouns .......... 3.65% complete.\n",
      "Extracting nouns .......... 3.91% complete.\n",
      "Extracting nouns .......... 4.17% complete.\n",
      "Extracting nouns .......... 4.43% complete.\n",
      "Extracting nouns .......... 4.69% complete.\n",
      "Extracting nouns .......... 4.95% complete.\n",
      "Extracting nouns .......... 5.21% complete.\n",
      "Extracting nouns .......... 5.47% complete.\n",
      "Extracting nouns .......... 5.73% complete.\n",
      "Extracting nouns .......... 5.99% complete.\n",
      "Extracting nouns .......... 6.25% complete.\n",
      "Extracting nouns .......... 6.51% complete.\n",
      "Extracting nouns .......... 6.77% complete.\n",
      "Extracting nouns .......... 7.03% complete.\n",
      "Extracting nouns .......... 7.29% complete.\n",
      "Extracting nouns .......... 7.55% complete.\n",
      "Extracting nouns .......... 7.81% complete.\n",
      "Extracting nouns .......... 8.07% complete.\n",
      "Extracting nouns .......... 8.33% complete.\n",
      "Extracting nouns .......... 8.59% complete.\n",
      "Extracting nouns .......... 8.85% complete.\n",
      "Extracting nouns .......... 9.11% complete.\n",
      "Extracting nouns .......... 9.38% complete.\n",
      "Extracting nouns .......... 9.64% complete.\n",
      "Extracting nouns .......... 9.90% complete.\n",
      "Extracting nouns .......... 10.16% complete.\n",
      "Extracting nouns .......... 10.42% complete.\n",
      "Extracting nouns .......... 10.68% complete.\n",
      "Extracting nouns .......... 10.94% complete.\n",
      "Extracting nouns .......... 11.20% complete.\n",
      "Extracting nouns .......... 11.46% complete.\n",
      "Extracting nouns .......... 11.72% complete.\n",
      "Extracting nouns .......... 11.98% complete.\n",
      "Extracting nouns .......... 12.24% complete.\n",
      "Extracting nouns .......... 12.50% complete.\n",
      "Extracting nouns .......... 12.76% complete.\n",
      "Extracting nouns .......... 13.02% complete.\n",
      "Extracting nouns .......... 13.28% complete.\n",
      "Extracting nouns .......... 13.54% complete.\n",
      "Extracting nouns .......... 13.80% complete.\n",
      "Extracting nouns .......... 14.06% complete.\n",
      "Extracting nouns .......... 14.32% complete.\n",
      "Extracting nouns .......... 14.58% complete.\n",
      "Extracting nouns .......... 14.84% complete.\n",
      "Extracting nouns .......... 15.10% complete.\n",
      "Extracting nouns .......... 15.36% complete.\n",
      "Extracting nouns .......... 15.62% complete.\n",
      "Extracting nouns .......... 15.89% complete.\n",
      "Extracting nouns .......... 16.15% complete.\n",
      "Extracting nouns .......... 16.41% complete.\n",
      "Extracting nouns .......... 16.67% complete.\n",
      "Extracting nouns .......... 16.93% complete.\n",
      "Extracting nouns .......... 17.19% complete.\n",
      "Extracting nouns .......... 17.45% complete.\n",
      "Extracting nouns .......... 17.71% complete.\n",
      "Extracting nouns .......... 17.97% complete.\n",
      "Extracting nouns .......... 18.23% complete.\n",
      "Extracting nouns .......... 18.49% complete.\n",
      "Extracting nouns .......... 18.75% complete.\n",
      "Extracting nouns .......... 19.01% complete.\n",
      "Extracting nouns .......... 19.27% complete.\n",
      "Extracting nouns .......... 19.53% complete.\n",
      "Extracting nouns .......... 19.79% complete.\n",
      "Extracting nouns .......... 20.05% complete.\n",
      "Extracting nouns .......... 20.31% complete.\n",
      "Extracting nouns .......... 20.57% complete.\n",
      "Extracting nouns .......... 20.83% complete.\n",
      "Extracting nouns .......... 21.09% complete.\n",
      "Extracting nouns .......... 21.35% complete.\n",
      "Extracting nouns .......... 21.61% complete.\n",
      "Extracting nouns .......... 21.88% complete.\n",
      "Extracting nouns .......... 22.14% complete.\n",
      "Extracting nouns .......... 22.40% complete.\n",
      "Extracting nouns .......... 22.66% complete.\n",
      "Extracting nouns .......... 22.92% complete.\n",
      "Extracting nouns .......... 23.18% complete.\n",
      "Extracting nouns .......... 23.44% complete.\n",
      "Extracting nouns .......... 23.70% complete.\n",
      "Extracting nouns .......... 23.96% complete.\n",
      "Extracting nouns .......... 24.22% complete.\n",
      "Extracting nouns .......... 24.48% complete.\n",
      "Extracting nouns .......... 24.74% complete.\n",
      "Extracting nouns .......... 25.00% complete.\n",
      "Extracting nouns .......... 25.26% complete.\n",
      "Extracting nouns .......... 25.52% complete.\n",
      "Extracting nouns .......... 25.78% complete.\n",
      "Extracting nouns .......... 26.04% complete.\n",
      "Extracting nouns .......... 26.30% complete.\n",
      "Extracting nouns .......... 26.56% complete.\n",
      "Extracting nouns .......... 26.82% complete.\n",
      "Extracting nouns .......... 27.08% complete.\n",
      "Extracting nouns .......... 27.34% complete.\n",
      "Extracting nouns .......... 27.60% complete.\n",
      "Extracting nouns .......... 27.86% complete.\n",
      "Extracting nouns .......... 28.12% complete.\n",
      "Extracting nouns .......... 28.39% complete.\n",
      "Extracting nouns .......... 28.65% complete.\n",
      "Extracting nouns .......... 28.91% complete.\n",
      "Extracting nouns .......... 29.17% complete.\n",
      "Extracting nouns .......... 29.43% complete.\n",
      "Extracting nouns .......... 29.69% complete.\n",
      "Extracting nouns .......... 29.95% complete.\n",
      "Extracting nouns .......... 30.21% complete.\n",
      "Extracting nouns .......... 30.47% complete.\n",
      "Extracting nouns .......... 30.73% complete.\n",
      "Extracting nouns .......... 30.99% complete.\n",
      "Extracting nouns .......... 31.25% complete.\n",
      "Extracting nouns .......... 31.51% complete.\n",
      "Extracting nouns .......... 31.77% complete.\n",
      "Extracting nouns .......... 32.03% complete.\n",
      "Extracting nouns .......... 32.29% complete.\n",
      "Extracting nouns .......... 32.55% complete.\n",
      "Extracting nouns .......... 32.81% complete.\n",
      "Extracting nouns .......... 33.07% complete.\n",
      "Extracting nouns .......... 33.33% complete.\n",
      "Extracting nouns .......... 33.59% complete.\n",
      "Extracting nouns .......... 33.85% complete.\n",
      "Extracting nouns .......... 34.11% complete.\n",
      "Extracting nouns .......... 34.38% complete.\n",
      "Extracting nouns .......... 34.64% complete.\n",
      "Extracting nouns .......... 34.90% complete.\n",
      "Extracting nouns .......... 35.16% complete.\n",
      "Extracting nouns .......... 35.42% complete.\n",
      "Extracting nouns .......... 35.68% complete.\n",
      "Extracting nouns .......... 35.94% complete.\n",
      "Extracting nouns .......... 36.20% complete.\n",
      "Extracting nouns .......... 36.46% complete.\n",
      "Extracting nouns .......... 36.72% complete.\n",
      "Extracting nouns .......... 36.98% complete.\n",
      "Extracting nouns .......... 37.24% complete.\n",
      "Extracting nouns .......... 37.50% complete.\n",
      "Extracting nouns .......... 37.76% complete.\n",
      "Extracting nouns .......... 38.02% complete.\n",
      "Extracting nouns .......... 38.28% complete.\n",
      "Extracting nouns .......... 38.54% complete.\n",
      "Extracting nouns .......... 38.80% complete.\n",
      "Extracting nouns .......... 39.06% complete.\n",
      "Extracting nouns .......... 39.32% complete.\n",
      "Extracting nouns .......... 39.58% complete.\n",
      "Extracting nouns .......... 39.84% complete.\n",
      "Extracting nouns .......... 40.10% complete.\n",
      "Extracting nouns .......... 40.36% complete.\n",
      "Extracting nouns .......... 40.62% complete.\n",
      "Extracting nouns .......... 40.89% complete.\n",
      "Extracting nouns .......... 41.15% complete.\n",
      "Extracting nouns .......... 41.41% complete.\n",
      "Extracting nouns .......... 41.67% complete.\n",
      "Extracting nouns .......... 41.93% complete.\n",
      "Extracting nouns .......... 42.19% complete.\n",
      "Extracting nouns .......... 42.45% complete.\n",
      "Extracting nouns .......... 42.71% complete.\n",
      "Extracting nouns .......... 42.97% complete.\n",
      "Extracting nouns .......... 43.23% complete.\n",
      "Extracting nouns .......... 43.49% complete.\n",
      "Extracting nouns .......... 43.75% complete.\n",
      "Extracting nouns .......... 44.01% complete.\n",
      "Extracting nouns .......... 44.27% complete.\n",
      "Extracting nouns .......... 44.53% complete.\n",
      "Extracting nouns .......... 44.79% complete.\n",
      "Extracting nouns .......... 45.05% complete.\n",
      "Extracting nouns .......... 45.31% complete.\n",
      "Extracting nouns .......... 45.57% complete.\n",
      "Extracting nouns .......... 45.83% complete.\n",
      "Extracting nouns .......... 46.09% complete.\n",
      "Extracting nouns .......... 46.35% complete.\n",
      "Extracting nouns .......... 46.61% complete.\n",
      "Extracting nouns .......... 46.88% complete.\n",
      "Extracting nouns .......... 47.14% complete.\n",
      "Extracting nouns .......... 47.40% complete.\n",
      "Extracting nouns .......... 47.66% complete.\n",
      "Extracting nouns .......... 47.92% complete.\n",
      "Extracting nouns .......... 48.18% complete.\n",
      "Extracting nouns .......... 48.44% complete.\n",
      "Extracting nouns .......... 48.70% complete.\n",
      "Extracting nouns .......... 48.96% complete.\n",
      "Extracting nouns .......... 49.22% complete.\n",
      "Extracting nouns .......... 49.48% complete.\n",
      "Extracting nouns .......... 49.74% complete.\n",
      "Extracting nouns .......... 50.00% complete.\n",
      "Extracting nouns .......... 50.26% complete.\n",
      "Extracting nouns .......... 50.52% complete.\n",
      "Extracting nouns .......... 50.78% complete.\n",
      "Extracting nouns .......... 51.04% complete.\n",
      "Extracting nouns .......... 51.30% complete.\n",
      "Extracting nouns .......... 51.56% complete.\n",
      "Extracting nouns .......... 51.82% complete.\n",
      "Extracting nouns .......... 52.08% complete.\n",
      "Extracting nouns .......... 52.34% complete.\n",
      "Extracting nouns .......... 52.60% complete.\n",
      "Extracting nouns .......... 52.86% complete.\n",
      "Extracting nouns .......... 53.12% complete.\n",
      "Extracting nouns .......... 53.39% complete.\n",
      "Extracting nouns .......... 53.65% complete.\n",
      "Extracting nouns .......... 53.91% complete.\n",
      "Extracting nouns .......... 54.17% complete.\n",
      "Extracting nouns .......... 54.43% complete.\n",
      "Extracting nouns .......... 54.69% complete.\n",
      "Extracting nouns .......... 54.95% complete.\n",
      "Extracting nouns .......... 55.21% complete.\n",
      "Extracting nouns .......... 55.47% complete.\n",
      "Extracting nouns .......... 55.73% complete.\n",
      "Extracting nouns .......... 55.99% complete.\n",
      "Extracting nouns .......... 56.25% complete.\n",
      "Extracting nouns .......... 56.51% complete.\n",
      "Extracting nouns .......... 56.77% complete.\n",
      "Extracting nouns .......... 57.03% complete.\n",
      "Extracting nouns .......... 57.29% complete.\n",
      "Extracting nouns .......... 57.55% complete.\n",
      "Extracting nouns .......... 57.81% complete.\n",
      "Extracting nouns .......... 58.07% complete.\n",
      "Extracting nouns .......... 58.33% complete.\n",
      "Extracting nouns .......... 58.59% complete.\n",
      "Extracting nouns .......... 58.85% complete.\n",
      "Extracting nouns .......... 59.11% complete.\n",
      "Extracting nouns .......... 59.38% complete.\n",
      "Extracting nouns .......... 59.64% complete.\n",
      "Extracting nouns .......... 59.90% complete.\n",
      "Extracting nouns .......... 60.16% complete.\n",
      "Extracting nouns .......... 60.42% complete.\n",
      "Extracting nouns .......... 60.68% complete.\n",
      "Extracting nouns .......... 60.94% complete.\n",
      "Extracting nouns .......... 61.20% complete.\n",
      "Extracting nouns .......... 61.46% complete.\n",
      "Extracting nouns .......... 61.72% complete.\n",
      "Extracting nouns .......... 61.98% complete.\n",
      "Extracting nouns .......... 62.24% complete.\n",
      "Extracting nouns .......... 62.50% complete.\n",
      "Extracting nouns .......... 62.76% complete.\n",
      "Extracting nouns .......... 63.02% complete.\n",
      "Extracting nouns .......... 63.28% complete.\n",
      "Extracting nouns .......... 63.54% complete.\n",
      "Extracting nouns .......... 63.80% complete.\n",
      "Extracting nouns .......... 64.06% complete.\n",
      "Extracting nouns .......... 64.32% complete.\n",
      "Extracting nouns .......... 64.58% complete.\n",
      "Extracting nouns .......... 64.84% complete.\n",
      "Extracting nouns .......... 65.10% complete.\n",
      "Extracting nouns .......... 65.36% complete.\n",
      "Extracting nouns .......... 65.62% complete.\n",
      "Extracting nouns .......... 65.89% complete.\n",
      "Extracting nouns .......... 66.15% complete.\n",
      "Extracting nouns .......... 66.41% complete.\n",
      "Extracting nouns .......... 66.67% complete.\n",
      "Extracting nouns .......... 66.93% complete.\n",
      "Extracting nouns .......... 67.19% complete.\n",
      "Extracting nouns .......... 67.45% complete.\n",
      "Extracting nouns .......... 67.71% complete.\n",
      "Extracting nouns .......... 67.97% complete.\n",
      "Extracting nouns .......... 68.23% complete.\n",
      "Extracting nouns .......... 68.49% complete.\n",
      "Extracting nouns .......... 68.75% complete.\n",
      "Extracting nouns .......... 69.01% complete.\n",
      "Extracting nouns .......... 69.27% complete.\n",
      "Extracting nouns .......... 69.53% complete.\n",
      "Extracting nouns .......... 69.79% complete.\n",
      "Extracting nouns .......... 70.05% complete.\n",
      "Extracting nouns .......... 70.31% complete.\n",
      "Extracting nouns .......... 70.57% complete.\n",
      "Extracting nouns .......... 70.83% complete.\n",
      "Extracting nouns .......... 71.09% complete.\n",
      "Extracting nouns .......... 71.35% complete.\n",
      "Extracting nouns .......... 71.61% complete.\n",
      "Extracting nouns .......... 71.88% complete.\n",
      "Extracting nouns .......... 72.14% complete.\n",
      "Extracting nouns .......... 72.40% complete.\n",
      "Extracting nouns .......... 72.66% complete.\n",
      "Extracting nouns .......... 72.92% complete.\n",
      "Extracting nouns .......... 73.18% complete.\n",
      "Extracting nouns .......... 73.44% complete.\n",
      "Extracting nouns .......... 73.70% complete.\n",
      "Extracting nouns .......... 73.96% complete.\n",
      "Extracting nouns .......... 74.22% complete.\n",
      "Extracting nouns .......... 74.48% complete.\n",
      "Extracting nouns .......... 74.74% complete.\n",
      "Extracting nouns .......... 75.00% complete.\n",
      "Extracting nouns .......... 75.26% complete.\n",
      "Extracting nouns .......... 75.52% complete.\n",
      "Extracting nouns .......... 75.78% complete.\n",
      "Extracting nouns .......... 76.04% complete.\n",
      "Extracting nouns .......... 76.30% complete.\n",
      "Extracting nouns .......... 76.56% complete.\n",
      "Extracting nouns .......... 76.82% complete.\n",
      "Extracting nouns .......... 77.08% complete.\n",
      "Extracting nouns .......... 77.34% complete.\n",
      "Extracting nouns .......... 77.60% complete.\n",
      "Extracting nouns .......... 77.86% complete.\n",
      "Extracting nouns .......... 78.12% complete.\n",
      "Extracting nouns .......... 78.39% complete.\n",
      "Extracting nouns .......... 78.65% complete.\n",
      "Extracting nouns .......... 78.91% complete.\n",
      "Extracting nouns .......... 79.17% complete.\n",
      "Extracting nouns .......... 79.43% complete.\n",
      "Extracting nouns .......... 79.69% complete.\n",
      "Extracting nouns .......... 79.95% complete.\n",
      "Extracting nouns .......... 80.21% complete.\n",
      "Extracting nouns .......... 80.47% complete.\n",
      "Extracting nouns .......... 80.73% complete.\n",
      "Extracting nouns .......... 80.99% complete.\n",
      "Extracting nouns .......... 81.25% complete.\n",
      "Extracting nouns .......... 81.51% complete.\n",
      "Extracting nouns .......... 81.77% complete.\n",
      "Extracting nouns .......... 82.03% complete.\n",
      "Extracting nouns .......... 82.29% complete.\n",
      "Extracting nouns .......... 82.55% complete.\n",
      "Extracting nouns .......... 82.81% complete.\n",
      "Extracting nouns .......... 83.07% complete.\n",
      "Extracting nouns .......... 83.33% complete.\n",
      "Extracting nouns .......... 83.59% complete.\n",
      "Extracting nouns .......... 83.85% complete.\n",
      "Extracting nouns .......... 84.11% complete.\n",
      "Extracting nouns .......... 84.38% complete.\n",
      "Extracting nouns .......... 84.64% complete.\n",
      "Extracting nouns .......... 84.90% complete.\n",
      "Extracting nouns .......... 85.16% complete.\n",
      "Extracting nouns .......... 85.42% complete.\n",
      "Extracting nouns .......... 85.68% complete.\n",
      "Extracting nouns .......... 85.94% complete.\n",
      "Extracting nouns .......... 86.20% complete.\n",
      "Extracting nouns .......... 86.46% complete.\n",
      "Extracting nouns .......... 86.72% complete.\n",
      "Extracting nouns .......... 86.98% complete.\n",
      "Extracting nouns .......... 87.24% complete.\n",
      "Extracting nouns .......... 87.50% complete.\n",
      "Extracting nouns .......... 87.76% complete.\n",
      "Extracting nouns .......... 88.02% complete.\n",
      "Extracting nouns .......... 88.28% complete.\n",
      "Extracting nouns .......... 88.54% complete.\n",
      "Extracting nouns .......... 88.80% complete.\n",
      "Extracting nouns .......... 89.06% complete.\n",
      "Extracting nouns .......... 89.32% complete.\n",
      "Extracting nouns .......... 89.58% complete.\n",
      "Extracting nouns .......... 89.84% complete.\n",
      "Extracting nouns .......... 90.10% complete.\n",
      "Extracting nouns .......... 90.36% complete.\n",
      "Extracting nouns .......... 90.62% complete.\n",
      "Extracting nouns .......... 90.89% complete.\n",
      "Extracting nouns .......... 91.15% complete.\n",
      "Extracting nouns .......... 91.41% complete.\n",
      "Extracting nouns .......... 91.67% complete.\n",
      "Extracting nouns .......... 91.93% complete.\n",
      "Extracting nouns .......... 92.19% complete.\n",
      "Extracting nouns .......... 92.45% complete.\n",
      "Extracting nouns .......... 92.71% complete.\n",
      "Extracting nouns .......... 92.97% complete.\n",
      "Extracting nouns .......... 93.23% complete.\n",
      "Extracting nouns .......... 93.49% complete.\n",
      "Extracting nouns .......... 93.75% complete.\n",
      "Extracting nouns .......... 94.01% complete.\n",
      "Extracting nouns .......... 94.27% complete.\n",
      "Extracting nouns .......... 94.53% complete.\n",
      "Extracting nouns .......... 94.79% complete.\n",
      "Extracting nouns .......... 95.05% complete.\n",
      "Extracting nouns .......... 95.31% complete.\n",
      "Extracting nouns .......... 95.57% complete.\n",
      "Extracting nouns .......... 95.83% complete.\n",
      "Extracting nouns .......... 96.09% complete.\n",
      "Extracting nouns .......... 96.35% complete.\n",
      "Extracting nouns .......... 96.61% complete.\n",
      "Extracting nouns .......... 96.88% complete.\n",
      "Extracting nouns .......... 97.14% complete.\n",
      "Extracting nouns .......... 97.40% complete.\n",
      "Extracting nouns .......... 97.66% complete.\n",
      "Extracting nouns .......... 97.92% complete.\n",
      "Extracting nouns .......... 98.18% complete.\n",
      "Extracting nouns .......... 98.44% complete.\n",
      "Extracting nouns .......... 98.70% complete.\n",
      "Extracting nouns .......... 98.96% complete.\n",
      "Extracting nouns .......... 99.22% complete.\n",
      "Extracting nouns .......... 99.48% complete.\n",
      "Extracting nouns .......... 99.74% complete.\n",
      "Extracting nouns .......... 100.00% complete.\n"
     ]
    }
   ],
   "source": [
    "def extract_nouns(text):\n",
    "    # Ensure the input is a string, not a list\n",
    "    if not isinstance(text, str):\n",
    "        text = \" \".join(text)\n",
    "    doc = nlp(text.lower())\n",
    "    return [token.text for token in doc if token.pos_ in (\"NOUN\", \"PROPN\")]\n",
    "\n",
    "# Apply to each dataframe in your list\n",
    "for i, df in enumerate(dataA_cleaned0):\n",
    "    df['captions_nouns'] = df['cleaned_caption'].apply(extract_nouns)\n",
    "    dataA_cleaned0[i] = df\n",
    "    print(f\"Extracting nouns .......... {(i+1)/len(dataA_cleaned0):.2%} complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c7789dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun-extracted data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# saving into pickle file\n",
    "noun_datafile = '../../data/cleaned_data_nouns.pkl'\n",
    "with open(noun_datafile, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"dataA_nouns\": dataA_cleaned0,\n",
    "        \"dataC_nouns\": dataC_cleaned0,\n",
    "        \"dataA_startID\": dataA_startID,\n",
    "        \"dataA_endID\": dataA_endID,\n",
    "        \"dataC_lastGoodID\": dataC_lastGoodID\n",
    "    }, f)\n",
    "print(\"Noun-extracted data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f15c3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun-extracted data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# load the new pickle file to verify\n",
    "noun_datafile = '../../data/cleaned_data_nouns.pkl'\n",
    "with open(noun_datafile, \"rb\") as f:\n",
    "    noun_stored_data = pickle.load(f)\n",
    "\n",
    "# Verify the contents\n",
    "print(\"Noun-extracted data loaded successfully.\")\n",
    "dataA1 = noun_stored_data[\"dataA_nouns\"]\n",
    "dataC1 = noun_stored_data[\"dataC_nouns\"]\n",
    "dataA_startID1 = noun_stored_data[\"dataA_startID\"]\n",
    "dataA_endID1 = noun_stored_data[\"dataA_endID\"]\n",
    "dataC_lastGoodID1 = noun_stored_data[\"dataC_lastGoodID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2fb35be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                caption      mean  precision  \\\n",
      "rank                                                                           \n",
      "0             I'm a congressman--obstruction is my job.  1.913043   0.094022   \n",
      "1     I'm what they mean when they say, 'The middle ...  1.842105   0.191381   \n",
      "2                     Does this suit make me look flat?  1.711111   0.112915   \n",
      "3       When the right woman comes along, I'll know it.  1.625000   0.116657   \n",
      "4     I used to lie in the gutter, but then I quit d...  1.617647   0.133610   \n",
      "\n",
      "      votes  not_funny  somewhat_funny  funny  \\\n",
      "rank                                            \n",
      "0        69         24              27     18   \n",
      "1        19          8               6      5   \n",
      "2        45         21              16      8   \n",
      "3        32         15              14      3   \n",
      "4        34         19               9      6   \n",
      "\n",
      "                            cleaned_caption                   captions_nouns  \n",
      "rank                                                                          \n",
      "0               congressmen obstruction job  [congressmen, obstruction, job]  \n",
      "1     mean say middle class getting stepped                          [class]  \n",
      "2                       suit make look flat                           [suit]  \n",
      "3               right woman come along know                          [woman]  \n",
      "4             used lie gutter quit drinking    [lie, gutter, quit, drinking]  \n"
     ]
    }
   ],
   "source": [
    "print(dataA1[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e8ab5",
   "metadata": {},
   "source": [
    "To count the occurrences of professions in the captions, we will use the 2018 U.S. Census occupation data as a reference.  \n",
    "This dataset provides a comprehensive list of job titles and their frequencies.  \n",
    "\n",
    "- The Census occupation indexes can be found [here](https://www.census.gov/topics/employment/industry-occupation/guidance/indexes.html).  \n",
    "- The explanation of the SOC (Standard Occupational Classification) codes is available [here](https://www.bls.gov/soc/2018/major_groups.htm).\n",
    "\n",
    "The problem with this approach is that occupations occur in their _colloquial_ form and not in their full _official_ title. This will make using the occupation indexes way too difficult. We must find a way to take the census data, and group it into smaller, colloquial terms (for example the occupation of midwife nurse from the census data should simply be nurse or midwife). The following approach is taken:\n",
    "\n",
    "- Clean the census data by lower casing, removing trailing spaces, taking away special characters like brackets and hyphens.\n",
    "- Some jobs are \"complicated title\" See \"simpler title\" -> lets cut all such instances as they are essentially the same as the simpler titles\n",
    "- There are some occupations of the form \"Analyst\\ specified type See type of analyst\" and \"Clerk\\any other specified   Code by duties\" etc. I want to remove these and make them simpler\n",
    "- It can be seen that some titles have entries like \"CFO (Chief Financial Officer)\" -> create a new column with alternative name, and delete from first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39a622f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andra\\OneDrive\\Desktop\\MA1_2025-2026\\Applied_data_analysis\\project\\ada-2025-project-adacore42\\_Other\\andras_analysis\\venv\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cleaning census data\n",
    "\n",
    "# Data\n",
    "census_loc = 'Alphabetical-Index-of-Occupations-December-2019_Final.xlsx'\n",
    "occupations = pd.read_excel(census_loc, skiprows=6)\n",
    "occupations.columns = ['occupation_name', 'industry_restriction', 'occupation_code', 'SOC_code']\n",
    "\n",
    "\n",
    "# See point 2 above\n",
    "def filter_complicated_titles(df):\n",
    "\n",
    "    pattern = r'.+\\sSee\\s+\"[^\"]+\"'  # any text followed by 'See \"...\"'\n",
    "    mask = df['occupation_name'].str.contains(pattern, na=False, case=False, regex=True)\n",
    "    filtered_df = df[~mask].reset_index(drop=True)\n",
    "    return filtered_df\n",
    "\n",
    "# See point 4 above\n",
    "def extract_bracketed(text):\n",
    "\n",
    "    # Extract bracketed text\n",
    "    match = re.search(r\"\\[([^\\]]+)\\]\", text) # Try to match square brackets first\n",
    "    if not match:\n",
    "        match = re.search(r\"\\(([^\\)]+)\\)\", text) # If none, try round parentheses\n",
    "    \n",
    "    if match:\n",
    "        alternative_name = match.group(1)\n",
    "    else:\n",
    "        alternative_name = None\n",
    "    # Remove bracketed text from original\n",
    "    cleaned_text = re.sub(r\"\\[.*?\\]|\\(.*?\\)\", \"\", text).strip()\n",
    "    return cleaned_text, alternative_name\n",
    "\n",
    "# See point 1 above\n",
    "def clean_occupation(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[\\[\\]\\(\\)\\-/,]\", \" \", text)  # remove brackets, hyphens, slashes, commas\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # collapse multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# See point 3 above\n",
    "def simplify_occupation(text):\n",
    "    text = str(text).lower()  # lowercase\n",
    "    # Patterns to cut off extra explanations\n",
    "    cut_patterns = [\n",
    "        r\"\\\\.*\",            # everything after backslash\n",
    "        r\"see.*\",           # everything after 'see'\n",
    "        r\"code by.*\",       # everything after 'code by'\n",
    "        r\"specified.*\",     # everything after 'specified'\n",
    "        r\"as ns.*\",         # everything after 'as ns'\n",
    "        r\"any other.*\",     # everything after 'any other'\n",
    "        r\"\\/.*\"              # everything after forward slash\n",
    "    ]\n",
    "    \n",
    "    for pattern in cut_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # collapse multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "occupations = filter_complicated_titles(occupations)\n",
    "occupations[['occupation_clean', 'alternative_name']] = occupations['occupation_name'].apply(lambda x: pd.Series(extract_bracketed(x)))\n",
    "\n",
    "occupations['occupation_clean'] = occupations['occupation_clean'].apply(clean_occupation)\n",
    "occupations['occupation_clean'] = occupations['occupation_clean'].apply(simplify_occupation)\n",
    "occupations_unique = occupations.drop_duplicates(subset='occupation_clean', keep='first').reset_index(drop=True) # Keep only unique cleaned occupations\n",
    "\n",
    "# Removing entries which are alternative names and main names too\n",
    "alt_matches = set(occupations['alternative_name'].dropna())\n",
    "occupations = occupations[~occupations['occupation_clean'].isin(alt_matches)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83653c71",
   "metadata": {},
   "source": [
    "The next step is bulkier: We want to make the occupations into colloquial forms \"midwife nurse\" or \"radiologist nurse\" should be both \"nurse\". For this, we need to use the _Spacy_ dataset and maybe _nltk_.\n",
    "\n",
    "The code below will break the entries of the census data into nouns, then counts words which occur often. This is done because, for example, there are lots of types of nurses, but in a joke, someone will never make a joke about a complicated title - only about a nurse. Or, even if it is a complicated title that poeple are joking about, it will be counted as an occurence of the more general field. This will allow us to not nitpick every job, only the somewhat wider categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66b2a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('operator', 3738), ('machine', 1752), ('supervisor', 1111), ('teacher', 783), ('worker', 756), ('clerk', 683), ('maker', 608), ('helper', 603), ('manager', 584), ('inspector', 504), ('tender', 466), ('sales', 447), ('engineer', 443), ('technician', 391), ('cutter', 386), ('installer', 338), ('attendant', 321), ('director', 320), ('hand', 305), ('driver', 299), ('service', 279), ('repairer', 265), ('equipment', 257), ('exc', 244), ('tester', 241), ('apprentice', 234), ('specialist', 230), ('car', 230), ('setter', 225), ('assembler', 220), ('press', 218), ('man', 215), ('agent', 212), ('mechanic', 205), ('officer', 195), ('aide', 186), ('analyst', 181), ('metal', 181), ('assistant', 180), ('control', 168), ('plant', 167), ('room', 164), ('mixer', 157), ('grinder', 155), ('maintenance', 151), ('builder', 149), ('health', 148), ('checker', 148), ('cleaner', 143), ('counselor', 139)]\n"
     ]
    }
   ],
   "source": [
    "#This is chatted - see how it works\n",
    "def extract_core_nouns(text):\n",
    "    \"\"\"\n",
    "    Extract nouns (or proper nouns) from occupation title.\n",
    "    \"\"\"\n",
    "    doc = nlp(text.lower())\n",
    "    nouns = [token.text for token in doc if token.pos_ in (\"NOUN\", \"PROPN\")]\n",
    "    return nouns\n",
    "\n",
    "all_nouns = []\n",
    "for occ in occupations['occupation_clean']:\n",
    "    all_nouns.extend(extract_core_nouns(occ))\n",
    "\n",
    "noun_freq = Counter(all_nouns)\n",
    "print(noun_freq.most_common(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa0e58ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health commissioner\n",
      "director of health education\n",
      "health education director\n",
      "director of health services\n",
      "health administrator\n",
      "health care administrator\n",
      "health director\n",
      "health information services manager\n",
      "manager medicine and health service\n",
      "mental health program manager\n",
      "public health administrator\n",
      "health insurance adjuster\n",
      "health program analyst\n",
      "health program specialist\n",
      "health systems analyst exc computer\n",
      "health systems analyst computer\n",
      "health actuary\n",
      "engineer public health\n",
      "microbiologist public health\n",
      "public health microbiologist\n",
      "health physicist radiation control\n",
      "health physicist\n",
      "health environmentalist\n",
      "health psychologist\n",
      "public health policy analyst\n",
      "technician biological exc health\n",
      "public health sanitarian technician\n",
      "technician public health\n",
      "construction health and safety technician\n",
      "environmental health sanitarian\n",
      "environmental health technologist\n",
      "health and safety inspector\n",
      "health officer field\n",
      "health sanitarian\n",
      "industrial safety and health specialist\n",
      "inspector health\n",
      "inspector occupational safety and health\n",
      "occupational health and safety specialist\n",
      "occupational health and safety technologist\n",
      "radiological health specialist\n",
      "technician occupational health and safety\n",
      "behavior health counselor\n",
      "behavioral health counselor\n",
      "bilingual mental health counselor\n",
      "clinical mental health counselor\n",
      "licensed clinical mental health counselor\n",
      "licensed mental health counselor\n",
      "licensed mental health counselor\n",
      "mental health consultant\n",
      "mental health counselor\n",
      "mental health therapist\n",
      "health care social worker\n",
      "home health care social worker\n",
      "public health social worker\n",
      "rural health consultant\n",
      "community mental health social worker\n",
      "community mental health worker\n",
      "community health aide\n",
      "community health education coordinator\n",
      "health educator\n",
      "lay health advocate\n",
      "peer health promoter\n",
      "public health advisor\n",
      "public health aide\n",
      "public health analyst\n",
      "public health educator\n",
      "public health instructor\n",
      "public health representative\n",
      "public health specialist\n",
      "public health technologist\n",
      "health social work professor\n",
      "public health professor\n",
      "teacher health\n",
      "teacher health administration\n",
      "teacher health assessment and treatment\n",
      "teacher health diagnostics\n",
      "teacher health education\n",
      "teacher health records technology\n",
      "teacher home care and home health aides\n",
      "teacher home care and home health aides\n",
      "teacher mental health aides\n",
      "teacher mental health aides\n",
      "teacher public health\n",
      "teacher public health aides\n",
      "teacher public health aides\n",
      "teacher health\n",
      "teacher health\n",
      "health science writer\n",
      "health technical writer\n",
      "dentist public health bachelors degree or higher\n",
      "public health dentist\n",
      "public health dietitian\n",
      "public health nutritionist\n",
      "county health officer\n",
      "health officer exc field\n",
      "public health doctor\n",
      "health therapist associate degree or higher\n",
      "public health veterinarian\n",
      "community health nurse\n",
      "nurse mental health\n",
      "occupational health nurse\n",
      "public health nurse\n",
      "public health staff nurse\n",
      "registered health nurse\n",
      "registered public health nurse\n",
      "supervisor health unit\n",
      "family health nurse practitioner\n",
      "dentist public health less than bachelors degree\n",
      "technician radiological health\n",
      "assistant therapy mental health\n",
      "behavioral health technician\n",
      "mental health technician\n",
      "technician behavioral health\n",
      "technician mental health\n",
      "health information coder\n",
      "health records technician\n",
      "technician health record\n",
      "child health associate\n",
      "technician biological health\n",
      "technician environmental health\n",
      "technician health type\n",
      "health consultant\n",
      "health informatics specialists\n",
      "health information analyst\n",
      "health information specialist\n",
      "health information systems technician\n",
      "health service coordinator\n",
      "public health service officer\n",
      "health care aide\n",
      "health care attendant\n",
      "home health aide\n",
      "home health attendant\n",
      "sitter home health aide\n",
      "health care aide\n",
      "health care attendant\n",
      "health aide\n",
      "health care aide\n",
      "health care attendant\n",
      "health care aide\n",
      "mental health aide\n",
      "mental health orderly\n",
      "assistant public health\n",
      "environmental health aide\n",
      "health education aide\n",
      "health equipment servicer\n",
      "health therapist less than associate degree\n",
      "manager health club\n",
      "sales health spa\n",
      "                           occupation_name industry_restriction  \\\n",
      "0                                  Admiral                  NaN   \n",
      "1                           Board chairman                  NaN   \n",
      "2                             Board member                  NaN   \n",
      "3                             Bureau chief            9370-9590   \n",
      "4            CEO (chief executive officer)                  NaN   \n",
      "...                                    ...                  ...   \n",
      "21536                         Wire wheeler                  NaN   \n",
      "21537                             Yarn man            1470-1670   \n",
      "21538                              Zanjero               (0690)   \n",
      "21539  University researcher  Code by type                  NaN   \n",
      "21540     Creative director Code by duties                  NaN   \n",
      "\n",
      "       occupation_code SOC_code       occupation_clean  \\\n",
      "0                 10.0  11-1011                admiral   \n",
      "1                 10.0  11-1011         board chairman   \n",
      "2                 10.0  11-1011           board member   \n",
      "3                 10.0  11-1011           bureau chief   \n",
      "4                 10.0  11-1011                    ceo   \n",
      "...                ...      ...                    ...   \n",
      "21536           9760.0  53-71XX           wire wheeler   \n",
      "21537           9760.0  53-71XX               yarn man   \n",
      "21538           9760.0  53-71XX                zanjero   \n",
      "21539              NaN      NaN  university researcher   \n",
      "21540              NaN      NaN      creative director   \n",
      "\n",
      "              alternative_name  \n",
      "0                         None  \n",
      "1                         None  \n",
      "2                         None  \n",
      "3                         None  \n",
      "4      chief executive officer  \n",
      "...                        ...  \n",
      "21536                     None  \n",
      "21537                     None  \n",
      "21538                     None  \n",
      "21539                     None  \n",
      "21540                     None  \n",
      "\n",
      "[21541 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# print all occurences of worker\n",
    "for occ in occupations['occupation_clean']:\n",
    "    if 'health' in occ.lower():\n",
    "        print(occ)\n",
    "\n",
    "unique_occupations = occupations['occupation_clean']\n",
    "# Make all operators into \"operator\"\n",
    "occupations.loc[unique_occupations.str.contains('operator', case=False), 'occupation_clean'] = 'operator' # Check conceptually... maybe ask the assitant\n",
    "# Make all cutters into \"cutter\"\n",
    "occupations.loc[unique_occupations.str.contains('cutter', case=False), 'occupation_clean'] = 'cutter'\n",
    "# Make all cleaners into \"cleaner\"\n",
    "occupations.loc[unique_occupations.str.contains('cleaner', case=False), 'occupation_clean'] = 'cleaner'\n",
    "# Make all drivers into \"driver\"\n",
    "occupations.loc[unique_occupations.str.contains('driver', case=False), 'occupation_clean'] = 'driver'\n",
    "# Make all inspectors into \"inspector\"\n",
    "occupations.loc[unique_occupations.str.contains('inspector', case=False), 'occupation_clean'] = 'inspector'\n",
    "# Make all technicians into \"technician\"\n",
    "occupations.loc[unique_occupations.str.contains('technician', case=False), 'occupation_clean'] = 'technician'\n",
    "# Make all sales into \"sales\"\n",
    "occupations.loc[unique_occupations.str.contains('sales', case=False), 'occupation_clean'] = 'sales' # What about in between director of sales???\n",
    "# Make all counselors into \"counselor\"\n",
    "occupations.loc[unique_occupations.str.contains('counselor', case=False), 'occupation_clean'] = 'counselor'\n",
    "#Make all analyst into \"analyst\"\n",
    "occupations.loc[unique_occupations.str.contains('analyst', case=False), 'occupation_clean'] = 'analyst'\n",
    "#make all teachers into \"teacher\"\n",
    "occupations.loc[unique_occupations.str.contains('teacher', case=False), 'occupation_clean'] = 'teacher'\n",
    "#make all clerks into \"clerk\"\n",
    "occupations.loc[unique_occupations.str.contains('clerk', case=False), 'occupation_clean'] = 'clerk'\n",
    "#make all nurses into \"nurse\"\n",
    "occupations.loc[unique_occupations.str.contains('nurse', case=False), 'occupation_clean'] = 'nurse'\n",
    "\n",
    "#remove duplicates from unique occupations\n",
    "occupations_unique = occupations.drop_duplicates(subset='occupation_clean', keep='first').reset_index(drop=True) # Keep only unique cleaned occupations\n",
    "print(occupations_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1577f19",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - Andras Analysis",
   "language": "python",
   "name": "andras_analysis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
